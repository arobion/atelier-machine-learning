{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique - Exercices tirés du MOOC d'Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données représente les chances de différents étudiants d'être admis à un programme universitaire en fonction de leurs résultats à deux examens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les données du fichier ex2data1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.083277</td>\n",
       "      <td>56.316372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.106665</td>\n",
       "      <td>96.511426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.024746</td>\n",
       "      <td>46.554014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.098787</td>\n",
       "      <td>87.420570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84.432820</td>\n",
       "      <td>43.533393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95.861555</td>\n",
       "      <td>38.225278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.013658</td>\n",
       "      <td>30.603263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>82.307053</td>\n",
       "      <td>76.481963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69.364589</td>\n",
       "      <td>97.718692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.538339</td>\n",
       "      <td>76.036811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.971052</td>\n",
       "      <td>89.207350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69.070144</td>\n",
       "      <td>52.740470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.946855</td>\n",
       "      <td>46.678574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>70.661510</td>\n",
       "      <td>92.927138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>76.978784</td>\n",
       "      <td>47.575964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>67.372028</td>\n",
       "      <td>42.838438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>89.676776</td>\n",
       "      <td>65.799366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50.534788</td>\n",
       "      <td>48.855812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.212061</td>\n",
       "      <td>44.209529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77.924091</td>\n",
       "      <td>68.972360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>62.271014</td>\n",
       "      <td>69.954458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>80.190181</td>\n",
       "      <td>44.821629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>93.114389</td>\n",
       "      <td>38.800670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>61.830206</td>\n",
       "      <td>50.256108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.785804</td>\n",
       "      <td>64.995681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>32.722833</td>\n",
       "      <td>43.307173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>64.039320</td>\n",
       "      <td>78.031688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72.346494</td>\n",
       "      <td>96.227593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>60.457886</td>\n",
       "      <td>73.094998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>58.840956</td>\n",
       "      <td>75.858448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>99.827858</td>\n",
       "      <td>72.369252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>47.264269</td>\n",
       "      <td>88.475865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>50.458160</td>\n",
       "      <td>75.809860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>60.455556</td>\n",
       "      <td>42.508409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>82.226662</td>\n",
       "      <td>42.719879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>88.913896</td>\n",
       "      <td>69.803789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>94.834507</td>\n",
       "      <td>45.694307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>67.319257</td>\n",
       "      <td>66.589353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>57.238706</td>\n",
       "      <td>59.514282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>80.366756</td>\n",
       "      <td>90.960148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>68.468522</td>\n",
       "      <td>85.594307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>42.075455</td>\n",
       "      <td>78.844786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.477702</td>\n",
       "      <td>90.424539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>78.635424</td>\n",
       "      <td>96.647427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>52.348004</td>\n",
       "      <td>60.769505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>94.094331</td>\n",
       "      <td>77.159105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>90.448551</td>\n",
       "      <td>87.508792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>55.482161</td>\n",
       "      <td>35.570703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>74.492692</td>\n",
       "      <td>84.845137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>89.845807</td>\n",
       "      <td>45.358284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1      exam2  admission\n",
       "0   34.623660  78.024693          0\n",
       "1   30.286711  43.894998          0\n",
       "2   35.847409  72.902198          0\n",
       "3   60.182599  86.308552          1\n",
       "4   79.032736  75.344376          1\n",
       "5   45.083277  56.316372          0\n",
       "6   61.106665  96.511426          1\n",
       "7   75.024746  46.554014          1\n",
       "8   76.098787  87.420570          1\n",
       "9   84.432820  43.533393          1\n",
       "10  95.861555  38.225278          0\n",
       "11  75.013658  30.603263          0\n",
       "12  82.307053  76.481963          1\n",
       "13  69.364589  97.718692          1\n",
       "14  39.538339  76.036811          0\n",
       "15  53.971052  89.207350          1\n",
       "16  69.070144  52.740470          1\n",
       "17  67.946855  46.678574          0\n",
       "18  70.661510  92.927138          1\n",
       "19  76.978784  47.575964          1\n",
       "20  67.372028  42.838438          0\n",
       "21  89.676776  65.799366          1\n",
       "22  50.534788  48.855812          0\n",
       "23  34.212061  44.209529          0\n",
       "24  77.924091  68.972360          1\n",
       "25  62.271014  69.954458          1\n",
       "26  80.190181  44.821629          1\n",
       "27  93.114389  38.800670          0\n",
       "28  61.830206  50.256108          0\n",
       "29  38.785804  64.995681          0\n",
       "..        ...        ...        ...\n",
       "70  32.722833  43.307173          0\n",
       "71  64.039320  78.031688          1\n",
       "72  72.346494  96.227593          1\n",
       "73  60.457886  73.094998          1\n",
       "74  58.840956  75.858448          1\n",
       "75  99.827858  72.369252          1\n",
       "76  47.264269  88.475865          1\n",
       "77  50.458160  75.809860          1\n",
       "78  60.455556  42.508409          0\n",
       "79  82.226662  42.719879          0\n",
       "80  88.913896  69.803789          1\n",
       "81  94.834507  45.694307          1\n",
       "82  67.319257  66.589353          1\n",
       "83  57.238706  59.514282          1\n",
       "84  80.366756  90.960148          1\n",
       "85  68.468522  85.594307          1\n",
       "86  42.075455  78.844786          0\n",
       "87  75.477702  90.424539          1\n",
       "88  78.635424  96.647427          1\n",
       "89  52.348004  60.769505          0\n",
       "90  94.094331  77.159105          1\n",
       "91  90.448551  87.508792          1\n",
       "92  55.482161  35.570703          0\n",
       "93  74.492692  84.845137          1\n",
       "94  89.845807  45.358284          1\n",
       "95  83.489163  48.380286          1\n",
       "96  42.261701  87.103851          1\n",
       "97  99.315009  68.775409          1\n",
       "98  55.340018  64.931938          1\n",
       "99  74.775893  89.529813          1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ex2data1.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez vous amuser à reproduire ce graphe avec les librairies Python, mais ne perdez pas trop de temps là-dessus non plus, il y a beaucoup à faire après!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpez vos données en une matrice X et un vecteur y et transformerz-les en array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "vector = np.ones(100, dtype = float)\n",
    "X = data.as_matrix(('exam1', 'exam2'))\n",
    "X = np.c_[vector, X]\n",
    "y = np.asarray(data.admission)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez bien les dimensions de vos structures de données (X.shape)  \n",
    "La matrice X doit-elle être de dimensions m x n ou bien m x (n+1) ? Quelle est la valeur de n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisez theta en un vecteur de zéros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de zéros vous faudra-t-il....?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(3, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation de l'hypothèse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revoyez l'équation de l'hypothèse de la régression logistique. Le produit de theta et de X est enveloppé dans une fonction g(z) qui correspond à la fonction sigmoïde. Nous allons commencer par coder cette fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _sigmoid_ qui applique la sigmoïde à son argument et retourne le résultat. Si elle reçoit une matrice ou un vecteur en input, elle doit s'appliquer sur chaque élément individuellement et retourner une structure de mêmes dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/ (1 + np.exp(-z)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez votre fonction. Quelle valeur renvoie une sigmoïde si z=0? Si z est grand? Si z est petit?  \n",
    "Il est possible que vous ayez un lorsque la fonction exponentielle reçoit des valeurs trop grandes. Dans ce cas vous pourrez éventuellement remplacer votre fonction sigmoïde par celle de scipy pour éviter des problèmes dans le reste de votre implémentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _predict_, qui correspond à l'hypohèse hθ(x), qui prend en paramètres X et theta, les multiplie (attention à l'ordre!), applique la fonction sigmoide, et se débrouille pour que le résultat final soit un vecteur de 1 et 0 correspondant aux catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15.40185632,   0.12831308,   0.12253314])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X, theta):\n",
    "    return (sigmoid(np.dot(X, theta)))\n",
    "predict(X, theta)\n",
    "theta.shape\n",
    "theta\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définissez la fonction de coût de votre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22461822686787256"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 0.0000001\n",
    "def cost(X, y, theta):\n",
    "    #return((-1 / X.shape[0]) * np.sum(y * np.log(predict(X, theta)) + (1 - y) * np.log(1 - predict(X, theta))) + (L/2 * X.shape[0])*(np.dot(theta, theta)))\n",
    "    return((-1 / X.shape[0]) * np.sum(y * np.log(predict(X, theta)) + (1 - y) * np.log(1 - predict(X, theta))))\n",
    "cost (X, y, theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appelez votre fonction _cost_. Vous devriez obtenir une valeur d'environ 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46364668009347026"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X, y, theta, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Écrivez une fonction _fit_ qui prend en arguments le vecteur X et le vecteur y des données d'entraînement et renvoie le vecteur de paramètres _theta_ qui a été appris, ainsi que l'évolution du coût"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter que l'exercice original ne fait pas faire la descente du gradient pour entraîner le modèle, mais plutôt une fonction d'optimisation avancée (_fminunc_ en Matlab). Nous tenterons de faire quand même la descente du gradient. Les plus téméraires peuvent aussi trouver une fonction d'optimisation équivalente en Python et comparer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y, theta, alpha, num_iters, L):\n",
    "   # Initialiser certaines variable utiles\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "   # Boucler sur le nombre d'itérations\n",
    "    for _ in range(num_iters):\n",
    "        theta = theta - (alpha / m) * (np.dot(predict(X, theta) - y, X)) + (L/m)*theta\n",
    "        J_history.append(cost(X, y, theta, L))\n",
    "    return(theta, J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancez l'apprentissage en appelant la fonction _fit_ et en prenant bien soin de récupérer le résultat de *theta* à la fin!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyez entre vous quelles valeurs semblent correctes pour alpha et num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(3, dtype=float)\n",
    "theta, J_history = fit(X, y, theta, 0.001, 1000000, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appelez la fonction _cost_ avec le nouveau theta après entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez obtenir une valeur autour de 0.203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22580447015141197"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X, y, theta, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On visualise maintenant l'évolution du coût en fonction du nombre d'itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1289feeb8>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1226ade80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation de votre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons évaluer la performance du modèle de deux façons:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluez la probabilité qu'un étudiant ayant obtenu 45 au premier examen, et 85 au deuxième, soit admis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez avoir une probabilité d'admission de 0.776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer l'exactitude (accuracy) des prédictions faites sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez votre fonction _predict_ sur les données d'entraînement (X) et récupérez les prédictions dans un vecteur p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6873047504036269"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [1, 45, 85]\n",
    "predict(p, theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez le pourcentage des éléments de p qui correspondent à ceux de y. Ça vous donne le score d'exactitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = predict(X, theta)\n",
    "for i in range(r.shape[0]):\n",
    "    if (r[i] > 0.5):\n",
    "        r[i] = 1\n",
    "    else:\n",
    "        r[i] = 0\n",
    "per = 0\n",
    "for j in range(r.shape[0]):\n",
    "    if (r[j] == y[j]):\n",
    "        per += 1\n",
    "per / 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez avoir un score d'environ 89.0 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Visualisez la frontière de décision (decision boundary) sur le graphe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ceux qui veulent découvrir Matplotlib, il faut ici afficher les données en deux nuages de points distincts (pour les deux classes) sur le même graphe, et aussi trouver une façon de tracer la fonction qui définit la frontière de décision. Amusez-vous bien, et surtout aidez-vous! Ça devrait donner un truc du genre:  \n",
    "<img src=\"figure-2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
